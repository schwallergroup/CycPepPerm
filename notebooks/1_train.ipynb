{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "This notebook goes through the steps to train tree-based models using 8-fold cross-validation and evaluate the performance on the training data.\n",
    "\n",
    "Make sure you have ***preprocessed the data first*** so that the inputs fit seemlessly with the model classes. Preprocessing is explained in ```0_process_data.ipynb```. Since these models are tree-based scaling the data is not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from cyc_pep_perm.data.paths import TRAIN_RANDOM_DW, TRAIN_RANDOM_MORDRED, MODEL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "The example is carried out with the provided descriptors from DataWarrior. If one wants to train and evaluate the model with mordred descriptors the code is the same, just change the paths to the input data (provded above in Housekeeping, too)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from cyc_pep_perm.models.randomforest import RF\n",
    "\n",
    "# instantiate class\n",
    "rf_regressor = RF()\n",
    "\n",
    "# traing a model using cross-validation\n",
    "# XXX: this will take some time especially if not on a GPU\n",
    "# and if you use all the default hyperparameters defined in the script to search over\n",
    "\n",
    "# define where to save the model to\n",
    "savepath = os.path.join(MODEL_PATH, 'rf_best8cv_datawarrior_random.pkl')\n",
    "\n",
    "model = rf_regressor.train(\n",
    "    datapath = TRAIN_RANDOM_DW,\n",
    "    savepath = savepath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# get predictions on the training data\n",
    "y_pred, rmse, r2 = rf_regressor.evaluate()\n",
    "print(f'Training RMSE = {rmse%0.2f}')\n",
    "print(f'Training R2 = {r2%0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# plot predictions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_true = rf_regressor.y\n",
    "\n",
    "plt.scatter(y_true, y_pred, color='r')\n",
    "plt.xlabel('True permeability [%]')\n",
    "plt.ylabel('Predicted permeability [%]')\n",
    "# plot rme and r2\n",
    "plt.text(0.05, 0.9, 'RMSE = %0.2f' % rmse, ha='left', va='center', transform=plt.gca().transAxes)\n",
    "plt.text(0.05, 0.85, 'R2 = %0.2f' % r2, ha='left', va='center', transform=plt.gca().transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# this plot tells you the contribution of different features to the prediction\n",
    "shap_values = rf_regressor.shap_explain(rf_regressor.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "The example is carried out with the provided descriptors from DataWarrior. If one wants to train and evaluate the model with mordred descriptors the code is the same, just change the paths to the input data (provded above in Housekeeping, too)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from cyc_pep_perm.models.xgboost import XGB\n",
    "\n",
    "# instantiate class\n",
    "xgb_regressor = XGB()\n",
    "\n",
    "# traing a model using cross-validation\n",
    "# XXX: this will take some time especially if not on a GPU\n",
    "# and if you use all the default hyperparameters defined in the script to search over\n",
    "\n",
    "# define where to save the model to\n",
    "savepath = os.path.join(MODEL_PATH, 'xgb_best8cv_datawarrior_random.pkl')\n",
    "\n",
    "model = xgb_regressor.train(\n",
    "    datapath = TRAIN_RANDOM_DW,\n",
    "    savepath = savepath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# get predictions on the training data\n",
    "y_pred, rmse, r2 = xgb_regressor.evaluate()\n",
    "print(f'Training RMSE = {rmse%0.2f}')\n",
    "print(f'Training R2 = {r2%0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# plot predictions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_true = xgb_regressor.y\n",
    "\n",
    "plt.scatter(y_true, y_pred, color='r')\n",
    "plt.xlabel('True permeability [%]')\n",
    "plt.ylabel('Predicted permeability [%]')\n",
    "# plot rme and r2\n",
    "plt.text(0.05, 0.9, 'RMSE = %0.2f' % rmse, ha='left', va='center', transform=plt.gca().transAxes)\n",
    "plt.text(0.05, 0.85, 'R2 = %0.2f' % r2, ha='left', va='center', transform=plt.gca().transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# this plot tells you the contribution of different features to the prediction\n",
    "shap_values = xgb_regressor.shap_explain(xgb_regressor.X)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
